by Linga Murthy Kanuri - Sunday, 3 August 2025, 6:38 PM

According to Jaafar's discussion, the deployment of intelligent, autonomous agents has accelerated due to advancements in large language models (LLMs) such as Claude 3.5 and Gemini 2.0. Agent-based systems(ABS) appeal to dynamic industries like finance and logistics because of their skills, especially in reasoning and task execution (Sapkota, Roumeliotis, and Karkee, 2025).

While decentralisation and modularity increase system flexibility, they also present problems with accountability, trust, and coordination. Jennings and Wooldridge (1998) warn that giving agents more autonomy may result in conflicting objectives or unpredictable outcomes. This raises the question of how organisations enforce consistency and compliance when agents act autonomously, such as in highly sensitive domains like autonomous cars or healthcare.

Furthermore, ethical and legal issues are taking centre stage. As the EU's AI Act and other comparable international laws develop, agent-based systems may be scrutinised for transparency, explainability, and decision accountability (European Commission, 2024). In autonomous decision-making, Russell and Norvig (2021) expressed concern that it is hard to assign blame when things go wrong without transparent audit trails.

Jaafar's post provides an excellent case for ABS, and I like his real-world examples. It also makes you want to learn more about how governance models or hybrid human-in-the-loop frameworks might help with full autonomy concerns.

References:

European Commission (2024) Artificial Intelligence Act: Proposal for a Regulation. Brussels: EU Publications.
Jennings, N.R. and Wooldridge, M. (1998) Agent Technology: Foundations, Applications, and Markets. Berlin: Springer.
Russell, S. and Norvig, P. (2021) Artificial Intelligence: A Modern Approach. 4th edn. Hoboken, NJ: Pearson.
Sapkota, R., Roumeliotis, K.I. and Karkee, M. (2025) 'AI agents vs. agentic AI: A conceptual taxonomy, applications and challenges', arXiv [Preprint]. Available at: https://doi.org/10.48550/arXiv.2505.10468 (Accessed: 3 August 2025).
