by Jaafar El Komati - Wednesday, 8 October 2025, 12:07 PM

The conversation about generative AI reveals a growing tension between innovation and responsibility. In my initial post, I highlighted the urgency of this debate, mentioning copyright issues, algorithmic bias, and the troubling potential for misuse (ScienceTimes, 2025; Wired, 2025). The concern that AI-generated outputs may take advantage of creative work without permission (AP News, 2024) sets the stage for an important discussion about who really owns AI-created content.

Murthy expands on this foundation by providing a deeper legal and ethical context. By discussing ongoing copyright debates and fairness issues in AI decision-making, Murthy stresses the need for updated legal frameworks and ethical governance (Borges, 2023; Rigotti & Fosch-Villaronga, 2024). Their view that AI can reinforce inequalities instead of reducing them connects with my initial warnings about bias. However, it also offers a hopeful perspective: collaboration among developers, policymakers, and scholars can help balance innovation with accountability (Floridi, 2023).

Abdulrahman enriches the discussion with practical insights, focusing on data transparency and traceability. His suggestions—dataset inventories, content provenance standards, and watermarking—provide clear paths for ethical AI use (Gebru et al., 2018; C2PA, 2023; Kirchenbauer et al., 2023). He importantly reframes accountability not as punishment but as clarity, making sure systems are auditable and responsive to misuse (NIST, 2023; Weidinger et al., 2022).

Together, the posts create a nuanced narrative: the power of generative AI is undeniable, but its promise relies on transparency, fairness, and regulation. Progress will depend not only on what AI can do but also on how responsibly we guide its development.



References

AP News. (2024). AI-generated child sexual abuse images are spreading. https://apnews.com/article/42186aaf8c9e27c39060f9678ebb6d7b

Borges, J. (2023). The legal battle over AI and copyright. Journal of Intellectual Property Law, 28(2), 112–134.

C2PA. (2023). Technical Specification. https://c2pa.org

Floridi, L. (2023). Ethics, dystopia and generative AI. AI & Society, 38(1), 1–10.

Gebru, T. et al. (2018). Datasheets for Datasets. arXiv:1803.09010.

Kirchenbauer, J. et al. (2023). A Watermark for Large Language Models. arXiv:2301.10226.

NIST. (2023). AI Risk Management Framework 1.0. https://www.nist.gov/itl/ai-risk-management-framework

ScienceTimes. (2025). Ethics in generative AI. https://www.sciencetimes.com/articles/60309/

Wired. (2025). OpenAI’s Sora is plagued by sexist, racist, and ableist biases. https://www.wired.com/story/openai-sora-video-generator-bias

Weidinger, L. et al. (2022). Taxonomy of Risks Posed by Language Models. arXiv:2112.04359.

Rigotti, C. & Fosch-Villaronga, E. (2024). Fairness, AI & recruitment. Computer Law & Security Review, 53, 105073.
