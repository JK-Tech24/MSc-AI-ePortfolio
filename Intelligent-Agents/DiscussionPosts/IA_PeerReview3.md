by Linga Murthy Kanuri - Thursday, 2 October 2025, 8:29 PM

The essay by Jaafar El Komati raises important ethical issues related to generative AI, specifically those pertaining to authorship, bias, and abuse. Ownership is a major concern since models that have been trained on large datasets frequently use creative works without permission. This illustrates the current legal controversies of whether work done by AI can be considered derivative or even original (Borges, 2023; ScienceTimes, 2025). These issues strongly underscore the urgent requirement for updated copyright standards.

Systemic bias in AI systems is also a concern. As discussed above, models like OpenAI Sora exemplify where and how bias can be exacerbated and disseminated (Wired, 2025). This is consistent with other research that also finds AI applications have a notable impact on fairness and transparency, especially in decision-making, law enforcement and recruitment (Rigotti & Fosch-Villaronga, 2024; Fjeld et al., 2020). Poorly governed AI is as likely to reinforce disparities as to diminish them.

Misuse presents the gravest danger. The advent of deepfakes (i.e., media that seem authentic but are manipulatively generated content) and the known generation of malign content through AI underpin how rapidly such innovations may become weaponised (AP News, 2024; Gupta et al., 2024; Pei et al., 2024). These dangers are not only the stuff of theory, but immediate societal challenges.

Nevertheless, there is still room for AI to enhance accessibility and originality. For thinkers like Floridi (2023), an ethically principled governance strategy is also crucial to guarantee that innovation at significant works for rather than against human flourishing. So, in addition to regulation, accountability, and transparency, ongoing collaboration between governments, developers, and researchers will allow us to see that generative AI grows in a way that fosters creativity while keeping society safe from harm.

References

AP News (2024) AI-generated child sexual abuse images are spreading. AP News. Available at: https://apnews.com/article/42186aaf8c9e27c39060f9678ebb6d7b [Accessed 2 October 2025].

Borges, J. (2023) ‘The legal battle over AI and copyright’, Journal of Intellectual Property Law, 28(2), pp. 112–134.

Fjeld, J., Achten, N., Hilligoss, H., Nagy, A. and Srikumar, M. (2020) Principled artificial intelligence: Mapping consensus in ethical and rights-based approaches to principles for AI. [Report]. Harvard University. Available at: https://dash.harvard.edu/bitstreams/c8d686a8-49e8-4128-969c-cb4a5f2ee145/download [Accessed 2 October 2025].

Floridi, L. (2023) ‘Ethics, dystopia and generative AI’, AI & Society, 38(1), pp. 1–10. Available at: https://doi.org/10.1007/s00146-022-01567-y [Accessed 2 October 2025].

Gupta, G., Raja, K., Gupta, M., et al. (2024) ‘A comprehensive review of deepfake detection using advanced machine learning and fusion methods’, Electronics, 13(1), p. 95. Available at: https://doi.org/10.3390/electronics13010095 [Accessed 2 October 2025].

Pei, G., Zhang, J., Hu, M., et al. (2024) ‘Deepfake generation and detection: A benchmark and survey’, arXiv preprint. arXiv:2403.17881. Available at: https://arxiv.org/abs/2403.17881 [Accessed 2 October 2025].

Rigotti, C. and Fosch-Villaronga, E. (2024) ‘Fairness, AI & recruitment’, Computer Law & Security Review, 53, p. 105073. Available at: https://doi.org/10.1016/j.clsr.2024.105073 [Accessed 2 October 2025].

ScienceTimes (2025) ‘Ethics in generative AI: addressing bias, misinformation, and intellectual property challenges’, ScienceTimes. Available at: https://www.sciencetimes.com/articles/60309/20250223/ethics-generative-ai-addressing-bias-misinformation-intellectual-property-challenges.htm [Accessed 2 October 2025].

Wired (2025) ‘OpenAI’s Sora is plagued by sexist, racist, and ableist biases’, Wired. Available at: https://www.wired.com/story/openai-sora-video-generator-bias [Accessed 2 October 2025].
