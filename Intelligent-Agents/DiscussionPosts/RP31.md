by Jaafar El Komati - Wednesday, 1 October 2025, 9:08 AM

Abdulrahman, I really liked how you clearly carried forward risks and practical methods. Talking about the costs hidden in data labeling, I got the most gone. Only the "large" moral debate is easy to focus on, such as prejudice or misinformation, but the interaction is made incomplete to see the labor behind the AI. Recent reports have highlighted how the anotation work is often outsourced in Global South, which raises questions of digital exploitation (Gray & Suri, 2019).

Your emphasis on data consent and traceability also takes place on time. This year is still coming out this year with cases against AI companies, it is clear that " managing data well " is not just a technical reform - it has become a legal and cultural requirement (Vincent, 2023). I think your suggestion to embed watermark for Provence is particularly interesting. It can help create accountability, although it also raises questions about enforcement in the open-source ecosystem.

I strongly agree with your call to keep humans in the loop. Transparency and human inspection feel like a bridge between innovation and trust. Without it, we risk the systems that look efficient but take silent loss.

 

References

Gray, M.L. & Suri, S. (2019). Ghost Work: How to Stop Silicon Valley from Building a New Global Underclass. Houghton Mifflin Harcourt.
Vincent, J. (2023). Artists file copyright lawsuits against AI image generators. The Verge. Available at: https://www.theverge.com
